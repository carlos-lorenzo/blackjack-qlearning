{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Tuple\n",
    "from enum import Enum\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import blackjack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class State:\n",
    "    hand_total: int\n",
    "    dealer_total: int\n",
    "    #usable_ace: bool\n",
    "    \n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self.hand_total, self.dealer_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class QTable:\n",
    "    q_table: Dict[State, List[float]] = field(default_factory=dict)\n",
    "    possible_player_totals: np.ndarray = field(init=False)\n",
    "    possible_dealer_totals: np.ndarray = field(init=False)\n",
    "    \n",
    "    def __post_init__(self) -> None:\n",
    "        self.possible_player_totals = np.arange(2, 22)\n",
    "        self.possible_dealer_totals = np.arange(1, 12)\n",
    "        \n",
    "        for hand_total in self.possible_player_totals:\n",
    "            for dealer_total in self.possible_dealer_totals:\n",
    "                self.q_table[State(hand_total, dealer_total)] = np.random.uniform(size=(2))\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, state: State) -> List[float]:\n",
    "        if state.hand_total > 21:\n",
    "            return [-2]\n",
    "        return self.q_table[state]\n",
    "    \n",
    "    def __setitem__(self, state: State, value: List[float]):\n",
    "        if state.hand_total > 21:\n",
    "            return\n",
    "        self.q_table[state] = value\n",
    "        \n",
    "    def policy(self, state: State) -> int:\n",
    "        if state.hand_total >= 21:\n",
    "            return 0\n",
    "        return np.argmax(self[state])\n",
    "    \n",
    "    def display_policy(self) -> None:\n",
    "        policy = np.zeros((self.possible_player_totals.shape[0], self.possible_dealer_totals.shape[0]))\n",
    "        for state in self.q_table:\n",
    "            policy[state.hand_total - 2, state.dealer_total - 1] = self.policy(state)\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        cax = ax.matshow(policy, cmap=plt.cm.RdYlGn)\n",
    "        \n",
    "        \n",
    "        ax.set_xticks(np.arange(len(self.possible_dealer_totals)))\n",
    "        ax.set_yticks(np.arange(len(self.possible_player_totals)))\n",
    "        \n",
    "        ax.set_xticklabels(self.possible_dealer_totals)\n",
    "        ax.set_yticklabels(self.possible_player_totals)\n",
    "        \n",
    "        ax.set_ylabel('Player Total')\n",
    "        ax.set_xlabel('Dealer Total')\n",
    "        \n",
    "        return fig\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, learning_rate: float = 0.1, discount_factor: float = 0.9, epsilon_greedy: float = 0.1, training_epochs: int = 1000) -> None:\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.chosen_epsilon_greedy = epsilon_greedy\n",
    "        self.epsilon_greedy = epsilon_greedy\n",
    "        self.training_epochs = training_epochs\n",
    "        self.current_epoch = 0\n",
    "        \n",
    "        self.q_table = QTable()\n",
    "        \n",
    "        self.deck = blackjack.Deck()\n",
    "        self.dealer = blackjack.Dealer()\n",
    "        self.player = blackjack.Player()    \n",
    "        \n",
    "        self.state = State(0, 0)\n",
    "        \n",
    "    def action(self, state: State) -> int:\n",
    "        if np.random.random() < self.epsilon_greedy:\n",
    "            return np.random.choice([0, 1])\n",
    "        else:\n",
    "            return self.q_table.policy(state)\n",
    "    \n",
    "    def reward(self, player_total: int, dealer_total: int) -> int:\n",
    "        if player_total > 21:\n",
    "            return -1\n",
    "        elif player_total == dealer_total:\n",
    "            return 0\n",
    "        elif dealer_total > 21:\n",
    "            return 1\n",
    "        elif player_total > dealer_total:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def start_turn(self) -> None:\n",
    "        self.deck.reset()\n",
    "        self.player.clear_hand()\n",
    "        self.player.playing = True\n",
    "        self.player.actions_taken = []\n",
    "        \n",
    "        self.dealer.clear_hand()\n",
    "        \n",
    "        self.player.hit(self.deck, save_action=False)\n",
    "        self.player.hit(self.deck, save_action=False)\n",
    "        self.dealer.hit(self.deck)\n",
    "        self.dealer.hit(self.deck)\n",
    "        \n",
    "    def play(self) -> int:\n",
    "        self.start_turn()\n",
    "        self.dealer.play(self.deck)\n",
    "        self.state = State(hand_total=self.player.hand.total, dealer_total=self.dealer.partial_total)\n",
    "        \n",
    "        if not self.player.playing: # blackjack hit\n",
    "            self.player.actions_taken.append({\n",
    "                \"action\": 0,\n",
    "                \"total\": self.player.hand.total,\n",
    "                \"usable_ace\": self.player.hand.usable_ace,\n",
    "                \"new_total\": self.player.hand.total,\n",
    "                \"reward\": 0\n",
    "            })\n",
    "        \n",
    "        while self.player.playing:\n",
    "            action = self.action(self.state)\n",
    "            self.player.play(action=action, deck=self.deck)\n",
    "            self.state.hand_total = self.player.hand.total\n",
    "\n",
    "        reward = self.reward(self.player.hand.total, self.dealer.hand.total)\n",
    "        \n",
    "        for action in self.player.actions_taken:\n",
    "            action[\"reward\"] = reward\n",
    "            \n",
    "        return reward\n",
    "    \n",
    "    \n",
    "    def learn(self) -> None:\n",
    "        for action in self.player.actions_taken:\n",
    "            action_state = State(action[\"total\"], self.dealer.partial_total)\n",
    "            new_state = State(action[\"new_total\"], self.dealer.partial_total)\n",
    "            self.q_table[action_state][action[\"action\"]] = (1 - self.learning_rate) * self.q_table[action_state][action[\"action\"]] + self.learning_rate * (action[\"reward\"] + self.discount_factor * np.max(self.q_table[new_state]))    \n",
    "    \n",
    "    def train(self) -> None:\n",
    "        self.epsilon_greedy = self.chosen_epsilon_greedy\n",
    "        for _ in range(self.training_epochs):\n",
    "            self.current_epoch += 1            \n",
    "            if self.current_epoch % 500 == 0:\n",
    "                print(f\"Epoch {self.current_epoch}\")\n",
    "            \n",
    "            self.play()\n",
    "            self.learn()\n",
    "    \n",
    "    \n",
    "    def benchmark(self) -> None:\n",
    "        self.epsilon_greedy = 0\n",
    "        hands_won = 0\n",
    "        hands_played = 0\n",
    "        \n",
    "        for _ in range(self.training_epochs):\n",
    "            if self.play() == 1:\n",
    "                hands_won += 1\n",
    "            hands_played += 1\n",
    "        print(f\"Hands won: {hands_won} / {hands_played} ({hands_won / hands_played * 100:.2f}%)\")\n",
    "        \n",
    "        self.q_table.display_policy()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    learning_rate=0.1,\n",
    "    discount_factor=0.9,\n",
    "    epsilon_greedy=0.1,\n",
    "    training_epochs=10000\n",
    ")\n",
    "agent.benchmark()\n",
    "agent.train()\n",
    "agent.benchmark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
