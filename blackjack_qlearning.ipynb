{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Tuple\n",
    "from enum import Enum\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import blackjack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class State:\n",
    "    hand_total: int\n",
    "    delear_partial_total: int\n",
    "    \n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self.hand_total, self.delear_partial_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "    HIT = 0\n",
    "    STAND = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class QTable:\n",
    "    table: Dict[State, List[float]] = field(default_factory=dict)\n",
    "    \n",
    "    def __post_init__(self) -> None:\n",
    "        possible_actions = [Action.HIT, Action.STAND]\n",
    "        possible_dealer_visible_totals = list(range(1, 12)) # Between 1 and 11\n",
    "        possible_hand_totals = list(range(2, 23)) # If hand_total > 21, then it is 22 in the q table, no matter how bigger than 21 it is (not that it will do anything since the game will be automatically ended)\n",
    "        \n",
    "        for total in possible_hand_totals:\n",
    "            for dealer_total in possible_dealer_visible_totals:\n",
    "                state = State(total, dealer_total)\n",
    "                self.table[state] = [0.0] * len(possible_actions)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, state: State) -> List[float]:\n",
    "        if state.hand_total > 21:\n",
    "            state.hand_total = 22\n",
    "        return self.table[state]\n",
    "    \n",
    "    def __setitem__(self, state: State, value: List[float]):\n",
    "        if state.hand_total > 21:\n",
    "            state.hand_total = 22\n",
    "        self.table[state] = value\n",
    "                \n",
    "    def policy(self, state: State, epsilon: float = None) -> Action:\n",
    "        if state.hand_total > 21:\n",
    "            return Action.STAND\n",
    "        if epsilon:\n",
    "            if np.random.random() < epsilon:\n",
    "                return Action(np.random.choice([0, 1]))\n",
    "        return Action(np.argmax(self[state]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, learning_rate: float = 0.1, discount_factor: float = 0.99, epsilon_greedy: float = 0.1, epochs: int = 1000) -> None:\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon_greedy = epsilon_greedy\n",
    "        self.epochs = epochs\n",
    "        self.current_epoch = 0\n",
    "        \n",
    "        self.q_table = QTable()\n",
    "        self.table = blackjack.Table()\n",
    "        self.states: List[State] = [State(-1, -1)]\n",
    "        self.episodes: List[List[Dict[str, State | Action | float]]] = []\n",
    "\n",
    "        self._hands_won = 0\n",
    "        self._hands_played = 0\n",
    "        self.win_rates = []\n",
    "    def reward_win_loss(self, player_total: int, dealer_total: int) -> float:\n",
    "       \n",
    "        if player_total > 21:\n",
    "            return -1\n",
    "        \n",
    "        if player_total > dealer_total:\n",
    "            return 1\n",
    "        \n",
    "        if dealer_total > 21:\n",
    "            return 1\n",
    "        \n",
    "        if dealer_total > player_total:\n",
    "            return -1\n",
    "        \n",
    "        if player_total == dealer_total:\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def reward_proximity(self, player_total: int, dealer_total: int) -> float:\n",
    "        player_total = player_total if player_total < 22 else 0\n",
    "        return 1 / (21 - player_total + 1e-1)\n",
    "                      \n",
    "\n",
    "    \n",
    "    def play_hand_recursive(self, players: List[blackjack.RecursivePlayer] = [], model_player: blackjack.Player = None) -> None:\n",
    "        if len(players) == 0:\n",
    "            players = [blackjack.RecursivePlayer(chosen_total, model_player.hand, actions_taken=[]) for chosen_total in model_player.hand.possible_totals]\n",
    "        else:\n",
    "            #return players\n",
    "            new_players = []\n",
    "            for player in players:\n",
    "                if player.playing:\n",
    "                    for total in player.possible_totals:\n",
    "                        new_players.append(blackjack.RecursivePlayer(total, player.hand, player.actions_taken, playing=player.playing))\n",
    "                        \n",
    "                else:\n",
    "                    reward = self.reward_proximity(min(player.hand.possible_totals), self.table.dealer.total)\n",
    "                    if self.reward_win_loss(min(player.hand.possible_totals), self.table.dealer.total) > 0:\n",
    "                        self._hands_won += len(player.actions_taken)\n",
    "                    \n",
    "                    self._hands_played += len(player.actions_taken)\n",
    "                    for action in player.actions_taken:\n",
    "                        \n",
    "                        action[\"reward\"] = reward\n",
    "                        action[\"state\"] = State(action[\"total\"], self.table.dealer.partial_total)\n",
    "                        action[\"current_total\"] = min(player.hand.possible_totals)\n",
    "                        if action not in self.episodes:\n",
    "                            self.episodes.append(action)\n",
    "                    \n",
    "            players = new_players\n",
    "        \n",
    "       \n",
    "        if len(players) == 0:\n",
    "            return \n",
    "            \n",
    "        \n",
    "        \n",
    "        next_card = self.table.deck.draw()\n",
    "        \n",
    "        for i, player in enumerate(players):\n",
    "            if player.playing:\n",
    "                action = self.q_table.policy(State(player.chosen_total, self.table.dealer.partial_total), self.epsilon_greedy)\n",
    "                if player.chosen_total > 21:\n",
    "                    player.stand()\n",
    "                    continue\n",
    "                \n",
    "                elif action == Action.HIT:  \n",
    "                    player.hit(next_card)\n",
    "                else:   \n",
    "                    player.stand()\n",
    "\n",
    "        \n",
    "                \n",
    "        return self.play_hand_recursive(players)\n",
    "    \n",
    "    def decay_epsilon(self) -> None:\n",
    "        self.epsilon_greedy *= 0.99965\n",
    "    \n",
    "    def update_q_table(self) -> None:\n",
    "        for episode in self.episodes:\n",
    "            state = episode[\"state\"]\n",
    "            action = episode[\"action\"]\n",
    "            reward = episode[\"reward\"]\n",
    "            new_total = episode[\"new_total\"]\n",
    "            #print((1 - self.learning_rate) * self.q_table[state][action.value] + self.learning_rate * (reward + self.discount_factor * max(self.q_table[state]) - self.q_table[state][action.value]))\n",
    "            self.q_table[state][action.value] = self.q_table[state][action.value] + self.learning_rate * (reward + self.discount_factor * max(self.q_table[State(new_total, self.table.dealer.partial_total)]) - self.q_table[state][action.value])\n",
    "            \n",
    "    \n",
    "    def train(self) -> None:\n",
    "        for _ in range(self.current_epoch, self.epochs + self.current_epoch + 1):\n",
    "            self.current_epoch += 1\n",
    "            self.table = blackjack.Table()\n",
    "            model_player = blackjack.Player()\n",
    "            \n",
    "            self.table.add_player(model_player)\n",
    "            self.table.start_turn()\n",
    "            self.table.dealer.play(self.table.deck)\n",
    "            self.play_hand_recursive(model_player=model_player)\n",
    "            self.update_q_table()\n",
    "            self.decay_epsilon()\n",
    "            \n",
    "            if self.current_epoch % 100 == 0:\n",
    "                table = np.array(list(self.q_table.table.values()))\n",
    "                expected_value = np.mean(table[np.argmax(table, axis=1)])\n",
    "                print(f\"Epoch: {self.current_epoch}\")\n",
    "                print(f\"Expected value: {expected_value}\")\n",
    "                \n",
    "                win_rate = (self._hands_won / self._hands_played) * 100\n",
    "                print(f\"Win rate: {win_rate}, [{win_rate * (1-self.epsilon_greedy)} - {win_rate * (1 + self.epsilon_greedy)}]\")\n",
    "                self.win_rates.append((self.current_epoch, win_rate))\n",
    "                \n",
    "                self._hands_played = 0\n",
    "                self._hands_won = 0\n",
    "                \n",
    "    def plot_win_rates(self) -> None:\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Win Rate (%)\")\n",
    "        \n",
    "        plt.plot([cc[0] for cc in self.win_rates], [cc[1] for cc in self.win_rates], label=\"Win Rate\", color=\"blue\")\n",
    "        plt.hlines(41.5, 0, self.current_epoch, color=\"red\", label=\"Theorical max win rate\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    learning_rate=0.1,\n",
    "    discount_factor=0.9,\n",
    "    epsilon_greedy=0.9,\n",
    "    epochs=10000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train()\n",
    "agent.plot_win_rates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
